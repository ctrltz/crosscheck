{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "from collections import defaultdict\n",
    "from sys import getsizeof"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### New API\n",
    "\n",
    "API key is required"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RELEASE = 'latest'\n",
    "DATASET = 'citations'\n",
    "API_KEY = 'NpToKVNU472E8fiIPEu6N1KLG1ECGEju6xZe3wgN'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## API -> Direct Co-Citations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import requests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PAPER_URL = 'https://api.semanticscholar.org/graph/v1/paper/{0}?fields={1}'\n",
    "PAPER_CITATION_FIELDS = 'citationCount,citations.paperId,citations.citationCount,' + \\\n",
    "    'citations.title,citations.url,citations.authors,citations.journal,citations.year'\n",
    "CITATIONS_URL = 'https://api.semanticscholar.org/graph/v1/paper/{0}/citations?fields={1}&offset={2}&limit={3}'\n",
    "CITATIONS_FIELDS = 'paperId,url,title,citationCount,authors,journal,year'\n",
    "MAX_LIMIT = 1000\n",
    "MAX_TOTAL_COUNT = 10000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "groups = [\n",
    "    # [\n",
    "    #     '10.1016/j.neuroimage.2011.01.057'\n",
    "    # ],\n",
    "    [\n",
    "        # '10.1038/nn.3101',\n",
    "        '10.1016/j.neuroimage.2012.03.048'\n",
    "    ],\n",
    "    [\n",
    "        # '10.1002/hbm.20346',\n",
    "        # '10.1016/j.clinph.2004.04.029',\n",
    "        # '10.1016/j.neuroimage.2011.11.084',\n",
    "        # '10.1016/j.neuroimage.2011.01.055',\n",
    "        # '10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C',\n",
    "        '10.1103/PhysRevLett.100.234101',\n",
    "        # '10.1098/rsta.2011.0081'\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_paper_data(doi, fields):\n",
    "    return requests.get(PAPER_URL.format(doi, fields)).json()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_citation_data(doi, fields, offset, limit=MAX_LIMIT):\n",
    "    if offset + limit >= MAX_TOTAL_COUNT:\n",
    "        limit = MAX_TOTAL_COUNT - offset - 1\n",
    "    return requests.get(CITATIONS_URL.format(doi, fields, offset, limit)).json()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def authors_compact(authors):\n",
    "    if not authors:\n",
    "        return ''\n",
    "    if len(authors) <= 3:\n",
    "        return ', '.join([a['name'] for a in authors])\n",
    "    else:\n",
    "        return f\"{authors[0]['name']} et al.\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def journal_compact(journal):\n",
    "    if not journal or 'name' not in journal:\n",
    "        return ''\n",
    "    result = journal['name']\n",
    "    if 'volume' in journal:\n",
    "        result += f\" {journal['volume']}\"\n",
    "    if 'pages' in journal:\n",
    "        result += f\":{journal['pages']}\"\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_graph(groups):\n",
    "    graph = nx.DiGraph()\n",
    "    node_groups = []\n",
    "    for group_papers in groups:\n",
    "        nodes = []\n",
    "        for paper_doi in group_papers:\n",
    "            # Get paper data\n",
    "            paper_data = get_paper_data(paper_doi, PAPER_CITATION_FIELDS)\n",
    "            paper_id = paper_data.get('paperId', None)\n",
    "            if not paper_id:\n",
    "                print(f'Failed to find paper: {paper_doi}')\n",
    "                continue\n",
    "\n",
    "            citations = paper_data.get('citations', [])\n",
    "            num_cit_retrieved = len(citations)\n",
    "            num_cit_total = paper_data['citationCount']\n",
    "            print(paper_doi)\n",
    "            print(f'Retrieved {num_cit_retrieved} / {num_cit_total} citations')\n",
    "            while num_cit_retrieved < num_cit_total:\n",
    "                new_citations = get_citation_data(paper_doi, CITATIONS_FIELDS, num_cit_retrieved)\n",
    "                citations.extend([cit['citingPaper'] for cit in new_citations.get('data', [])])\n",
    "                num_cit_retrieved = new_citations.get('next', None)\n",
    "                if num_cit_retrieved:\n",
    "                    assert len(citations) == num_cit_retrieved, paper_doi\n",
    "                else:\n",
    "                    assert len(citations) == num_cit_total, paper_doi\n",
    "                    num_cit_retrieved = num_cit_total\n",
    "                print(f'Retrieved {num_cit_retrieved} / {num_cit_total} citations')\n",
    "\n",
    "            # Add reversed edges to the graph for BFS\n",
    "            citation_nodes = [(cit['paperId'], \n",
    "                              dict(citationCount=cit['citationCount'],\n",
    "                                   url=cit['url'], title=cit['title'],\n",
    "                                   year=cit.get('year', ''), \n",
    "                                   authors=authors_compact(cit.get('authors', [])),\n",
    "                                   journal=journal_compact(cit.get('journal', {}))))\n",
    "                              for cit in citations\n",
    "                              if cit['paperId']]\n",
    "            citation_edges = [(paper_id, cit['paperId']) \n",
    "                              for cit in citations\n",
    "                              if cit['paperId']]  # skip None?\n",
    "\n",
    "            # Add the node and incoming edges to the graph\n",
    "            nodes.append(paper_id)\n",
    "            graph.add_node(paper_id, citationCount=num_cit_total)            \n",
    "            graph.add_nodes_from(citation_nodes)\n",
    "            graph.add_edges_from(citation_edges)\n",
    "\n",
    "        node_groups.append(nodes)\n",
    "\n",
    "    return graph, node_groups"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graph, node_groups = build_graph(groups)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())\n",
    "print(node_groups)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "crosschecked = set(graph.nodes)\n",
    "for group_nodes in node_groups:\n",
    "    reachable = nx.bfs_layers(graph, group_nodes)\n",
    "    print(next(reachable))  # skip group nodes in layer 0\n",
    "    crosschecked &= set(next(reachable))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(crosschecked)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "crosschecked_data = [dict(paperId=n[0], **n[1]) for n in graph.nodes(data=True) if n[0] in crosschecked]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "crosschecked_df = pd.DataFrame(crosschecked_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "crosschecked_df.sort_values(by='citationCount', ascending=False).head(n=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Old Way"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DOWNLOAD_URL = 'https://s3-us-west-2.amazonaws.com/ai2-s2-research-public/open-corpus/2022-05-01/s2-corpus-{0:03d}.gz'\n",
    "FILE_NAME_GZ = 's2-corpus-{0:03d}.gz'\n",
    "FILE_NAME = 's2-corpus-{0:03d}'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def to_numeric(sha1_id):\n",
    "    if sha1_id not in paper_ids:\n",
    "        new_id = len(paper_ids)\n",
    "        paper_ids[sha1_id] = new_id\n",
    "        paper_index[new_id] = sha1_id\n",
    "    return paper_ids[sha1_id]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def update_citations(corpus_id):\n",
    "    p = subprocess.Popen(['wget', DOWNLOAD_URL.format(corpus_id)], \n",
    "                         stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    p.communicate()\n",
    "    p.wait()\n",
    "    \n",
    "    p = subprocess.Popen(['gzip', '-d', FILE_NAME_GZ.format(corpus_id)], \n",
    "                         stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    p.communicate()\n",
    "    p.wait()\n",
    "    \n",
    "    filename = FILE_NAME.format(corpus_id)\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            paper_id = to_numeric(data['id'])\n",
    "            for cit_id in data['inCitations']:\n",
    "                citations[to_numeric(cit_id)].add(paper_id)\n",
    "            citations[paper_id].update(set(to_numeric(cit_id) for cit_id in data['outCitations']))\n",
    "            \n",
    "    p = subprocess.Popen(['rm', filename], \n",
    "                         stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    p.communicate()\n",
    "    p.wait()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "citations = defaultdict(set)\n",
    "paper_ids = {}\n",
    "paper_index = {}\n",
    "\n",
    "print(f'Corpus ID\\tNumPapers\\tSizePapers\\tNumCitations\\tSizeCitations')\n",
    "for corpus_id in range(10):\n",
    "    update_citations(corpus_id)\n",
    "    num_papers = len(paper_index)\n",
    "    size_papers = getsizeof(paper_ids) + getsizeof(paper_index)\n",
    "    num_citations = sum([len(s) for s in citations.values()])\n",
    "    size_citations = getsizeof(citations)\n",
    "    print(f'{corpus_id}\\t{num_papers}\\t{size_papers}\\t{num_citations}\\t{size_citations}')\n",
    "    if size_papers + size_citations > 500_000_000:\n",
    "        print('Alarm!')\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}